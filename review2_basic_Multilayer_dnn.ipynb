{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# 데이터\n",
    "x = np.array([range(1,101), range(311,411), range(100)]).T  \n",
    "y = np.array([range(101,201), range(711,811), range(100)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, 311,   0],\n",
       "       [  2, 312,   1],\n",
       "       [  3, 313,   2],\n",
       "       [  4, 314,   3],\n",
       "       [  5, 315,   4],\n",
       "       [  6, 316,   5],\n",
       "       [  7, 317,   6],\n",
       "       [  8, 318,   7],\n",
       "       [  9, 319,   8],\n",
       "       [ 10, 320,   9]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10]     # 첫번째 열은 +100, 두번째 열은 +400, 세번째 열은 +0, 즉 열마다 다른 규칙을 예쁜 패턴으로 가지고 잇음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 711,   0],\n",
       "       [102, 712,   1],\n",
       "       [103, 713,   2],\n",
       "       [104, 714,   3],\n",
       "       [105, 715,   4],\n",
       "       [106, 716,   5],\n",
       "       [107, 717,   6],\n",
       "       [108, 718,   7],\n",
       "       [109, 719,   8],\n",
       "       [110, 720,   9]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 10067.8914 - mse: 10067.8877 - acc: 0.9900\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2528 - mse: 2.2528 - acc: 1.0000\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0012 - mse: 0.0012 - acc: 1.0000    \n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - acc: 1.0000\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 86.4404 - mse: 86.4404 - acc: 1.0000\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1829.3488 - mse: 1829.3497 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 20.3116 - mse: 20.3116 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0071 - mse: 0.0071 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 6.0583e-05 - mse: 6.0584e-05 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1775e-07 - mse: 4.1775e-07 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8958e-08 - mse: 1.8958e-08 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.9381e-09 - mse: 2.9381e-09 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.6108e-09 - mse: 3.6108e-09 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4880e-09 - mse: 3.4880e-09 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8867e-09 - mse: 2.8867e-09 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6735e-08 - mse: 1.6735e-08 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1429e-08 - mse: 1.1429e-08 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.2158e-08 - mse: 1.2158e-08 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.3035e-08 - mse: 4.3035e-08 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 6.6741e-08 - mse: 6.6741e-08 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 9.3342e-09 - mse: 9.3342e-09 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0194e-08 - mse: 2.0194e-08 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.8676e-08 - mse: 4.8676e-08 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0021 - mse: 0.0021 - acc: 1.0000    \n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.9304 - mse: 0.9304 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 31.9512 - mse: 31.9511 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3437.9915 - mse: 3437.9919 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 725.3043 - mse: 725.3044 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3029 - mse: 0.3029 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.0959e-04 - mse: 7.0959e-04 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.1307e-07 - mse: 4.1307e-07 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3534e-09 - mse: 3.3534e-09 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5079e-09 - mse: 2.5079e-09 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.7727e-09 - mse: 2.7727e-09 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5943e-09 - mse: 2.5943e-09 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2998e-09 - mse: 3.2998e-09 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.4155e-09 - mse: 3.4155e-09 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.3894e-09 - mse: 3.3894e-09 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4.0865e-09 - mse: 4.0865e-09 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.2467e-09 - mse: 3.2467e-09 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 5.1614e-09 - mse: 5.1614e-09 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.7387e-08 - mse: 1.7387e-08 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 5.4249e-09 - mse: 5.4249e-09 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.3728e-09 - mse: 7.3728e-09 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 6.9843e-09 - mse: 6.9843e-09 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1005e-08 - mse: 2.1005e-08 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9200e-07 - mse: 1.9200e-07 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 5.5935e-05 - mse: 5.5935e-05 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 0.0063 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2003 - mse: 0.2003 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20573afad88>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델구성\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3)) \n",
    "model.add(Dense(8)) \n",
    "model.add(Dense(16)) \n",
    "model.add(Dense(520))\n",
    "model.add(Dense(848))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(3)) \n",
    "# 훈련\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse','acc'])\n",
    "model.fit(x,y, epochs=50, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 할 때, 열 3개치고는 데이터가 적은 것 같다\n",
    "mse의 변화 양상이 편차가 크다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n",
      "loss : 0.1834251081943512\n",
      "mse : 0.18342508375644684\n",
      "acc : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "loss, mse, acc = model.evaluate(x, y, batch_size=1)\n",
    "print(\"loss :\", loss)\n",
    "print(\"mse :\", mse)\n",
    "print(\"acc :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict 값은 [[101. 711.   0.]\n",
      " [102. 712.   1.]\n",
      " [103. 713.   2.]\n",
      " [104. 714.   3.]\n",
      " [105. 715.   4.]\n",
      " [106. 716.   5.]\n",
      " [107. 717.   6.]\n",
      " [108. 718.   7.]\n",
      " [109. 719.   8.]\n",
      " [110. 720.   9.]\n",
      " [111. 721.  10.]\n",
      " [112. 722.  11.]\n",
      " [113. 723.  12.]\n",
      " [114. 724.  13.]\n",
      " [115. 725.  14.]\n",
      " [116. 726.  15.]\n",
      " [117. 727.  16.]\n",
      " [118. 728.  17.]\n",
      " [119. 729.  18.]\n",
      " [120. 730.  19.]\n",
      " [121. 731.  20.]\n",
      " [122. 732.  21.]\n",
      " [123. 733.  22.]\n",
      " [124. 734.  23.]\n",
      " [125. 735.  24.]\n",
      " [126. 736.  25.]\n",
      " [127. 737.  26.]\n",
      " [128. 738.  27.]\n",
      " [129. 739.  28.]\n",
      " [130. 739.  29.]\n",
      " [131. 740.  30.]\n",
      " [132. 741.  31.]\n",
      " [133. 742.  32.]\n",
      " [134. 743.  33.]\n",
      " [135. 744.  34.]\n",
      " [136. 745.  35.]\n",
      " [137. 746.  36.]\n",
      " [138. 747.  37.]\n",
      " [139. 748.  38.]\n",
      " [140. 749.  39.]\n",
      " [141. 750.  40.]\n",
      " [142. 751.  41.]\n",
      " [143. 752.  42.]\n",
      " [144. 753.  43.]\n",
      " [145. 754.  44.]\n",
      " [146. 755.  45.]\n",
      " [147. 756.  46.]\n",
      " [148. 757.  47.]\n",
      " [149. 758.  48.]\n",
      " [150. 759.  49.]\n",
      " [151. 760.  50.]\n",
      " [152. 761.  51.]\n",
      " [153. 762.  52.]\n",
      " [154. 763.  53.]\n",
      " [155. 764.  54.]\n",
      " [156. 765.  55.]\n",
      " [157. 766.  56.]\n",
      " [158. 767.  57.]\n",
      " [159. 768.  58.]\n",
      " [160. 769.  59.]\n",
      " [161. 770.  60.]\n",
      " [162. 771.  61.]\n",
      " [163. 772.  62.]\n",
      " [164. 773.  63.]\n",
      " [165. 774.  64.]\n",
      " [166. 775.  65.]\n",
      " [167. 776.  66.]\n",
      " [168. 777.  67.]\n",
      " [169. 778.  68.]\n",
      " [170. 779.  69.]\n",
      " [171. 780.  70.]\n",
      " [172. 781.  71.]\n",
      " [173. 782.  72.]\n",
      " [174. 783.  73.]\n",
      " [175. 784.  74.]\n",
      " [176. 785.  75.]\n",
      " [177. 786.  76.]\n",
      " [178. 787.  77.]\n",
      " [179. 788.  78.]\n",
      " [180. 789.  79.]\n",
      " [181. 790.  80.]\n",
      " [182. 791.  81.]\n",
      " [183. 792.  82.]\n",
      " [184. 793.  83.]\n",
      " [185. 794.  84.]\n",
      " [186. 795.  85.]\n",
      " [187. 796.  86.]\n",
      " [188. 797.  87.]\n",
      " [189. 798.  88.]\n",
      " [190. 799.  89.]\n",
      " [191. 800.  90.]\n",
      " [192. 801.  91.]\n",
      " [193. 802.  92.]\n",
      " [194. 803.  93.]\n",
      " [195. 804.  94.]\n",
      " [196. 805.  95.]\n",
      " [197. 806.  96.]\n",
      " [198. 807.  97.]\n",
      " [199. 808.  98.]\n",
      " [200. 809.  99.]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x)\n",
    "print('y_predict 값은', np.round(y_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### 역피라미드형으로 만들었을때\n",
    "실제로 (엄청엄청 튜닝했을때..) 열1, 열2는 완벽하게 맞추고 있다,\n",
    "열 3은 절대 못맞춤..  -> 각각 쪼개질때는 쪼개서 학습해야 할 것 같다. 얘도 멀티를 못하는듯,,\n",
    "-> 그렇다면 y를 1열로 모았을때는..? (이 경우 2열이 영향력1.0으로 알아서 반영할 줄 알아야 결과적으로 맞춘다. )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### 다이아몬드형으로 만들었을때\n",
    "100% 맞춤\n",
    "dnn은 다이아몬드형이 최고다... layer를 어떤 형태로 만드냐에 따라 성능차이가 매우매우 크다는 것을 느꼈다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(range(711,811)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 24022.5662 - mse: 24022.5547 - acc: 0.0000e+00\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 64.4189 - mse: 64.4190 - acc: 0.1300\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0520 - mse: 0.0520 - acc: 0.9500\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1785e-04 - mse: 1.1785e-04 - acc: 1.0000\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.9078e-06 - mse: 1.9078e-06 - acc: 1.0000\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5013e-08 - mse: 1.5013e-08 - acc: 1.0000\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 8.1956e-09 - mse: 8.1956e-09 - acc: 1.0000\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8179e-08 - mse: 1.8179e-08 - acc: 1.0000\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 9.7975e-09 - mse: 9.7975e-09 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.4878e-09 - mse: 7.4878e-09 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.4438e-08 - mse: 2.4438e-08 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1139e-08 - mse: 1.1139e-08 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1861e-07 - mse: 1.1861e-07 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.5363e-06 - mse: 3.5363e-06 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.6320e-07 - mse: 1.6320e-07 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.2661e-07 - mse: 2.2661e-07 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.5824e-05 - mse: 7.5824e-05 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 9.5440e-06 - mse: 9.5440e-06 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - acc: 0.9900  \n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.1805 - mse: 2.1805 - acc: 0.4600\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 8.8518 - mse: 8.8518 - acc: 0.1300\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 4522.1897 - mse: 4522.1895 - acc: 0.0400\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 71.6993 - mse: 71.6993 - acc: 0.1500\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0194 - mse: 0.0194 - acc: 0.9800\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.5009e-05 - mse: 3.5009e-05 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0364e-07 - mse: 1.0364e-07 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.8976e-09 - mse: 7.8976e-09 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 7.0781e-09 - mse: 7.0781e-09 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.0431e-08 - mse: 1.0431e-08 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.5385e-08 - mse: 1.5385e-08 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20575d7dbc8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3)) \n",
    "model.add(Dense(8)) \n",
    "model.add(Dense(16)) \n",
    "model.add(Dense(520))\n",
    "model.add(Dense(848))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1)) \n",
    "# 훈련\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mse','acc'])\n",
    "model.fit(x,y, epochs=30, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step\n",
      "y_predict 값은 [[711.]\n",
      " [712.]\n",
      " [713.]\n",
      " [714.]\n",
      " [715.]\n",
      " [716.]\n",
      " [717.]\n",
      " [718.]\n",
      " [719.]\n",
      " [720.]\n",
      " [721.]\n",
      " [722.]\n",
      " [723.]\n",
      " [724.]\n",
      " [725.]\n",
      " [726.]\n",
      " [727.]\n",
      " [728.]\n",
      " [729.]\n",
      " [730.]\n",
      " [731.]\n",
      " [732.]\n",
      " [733.]\n",
      " [734.]\n",
      " [735.]\n",
      " [736.]\n",
      " [737.]\n",
      " [738.]\n",
      " [739.]\n",
      " [740.]\n",
      " [741.]\n",
      " [742.]\n",
      " [743.]\n",
      " [744.]\n",
      " [745.]\n",
      " [746.]\n",
      " [747.]\n",
      " [748.]\n",
      " [749.]\n",
      " [750.]\n",
      " [751.]\n",
      " [752.]\n",
      " [753.]\n",
      " [754.]\n",
      " [755.]\n",
      " [756.]\n",
      " [757.]\n",
      " [758.]\n",
      " [759.]\n",
      " [760.]\n",
      " [761.]\n",
      " [762.]\n",
      " [763.]\n",
      " [764.]\n",
      " [765.]\n",
      " [766.]\n",
      " [767.]\n",
      " [768.]\n",
      " [769.]\n",
      " [770.]\n",
      " [771.]\n",
      " [772.]\n",
      " [773.]\n",
      " [774.]\n",
      " [775.]\n",
      " [776.]\n",
      " [777.]\n",
      " [778.]\n",
      " [779.]\n",
      " [780.]\n",
      " [781.]\n",
      " [782.]\n",
      " [783.]\n",
      " [784.]\n",
      " [785.]\n",
      " [786.]\n",
      " [787.]\n",
      " [788.]\n",
      " [789.]\n",
      " [790.]\n",
      " [791.]\n",
      " [792.]\n",
      " [793.]\n",
      " [794.]\n",
      " [795.]\n",
      " [796.]\n",
      " [797.]\n",
      " [798.]\n",
      " [799.]\n",
      " [800.]\n",
      " [801.]\n",
      " [802.]\n",
      " [803.]\n",
      " [804.]\n",
      " [805.]\n",
      " [806.]\n",
      " [807.]\n",
      " [808.]\n",
      " [809.]\n",
      " [810.]]\n",
      "loss : 4.060566425323487e-09\n",
      "mse : 4.060566549668465e-09\n",
      "acc : 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, mse, acc = model.evaluate(x, y, batch_size=1)\n",
    "y_predict = model.predict(x)\n",
    "print('y_predict 값은', np.round(y_predict))\n",
    "print(\"loss :\", loss)\n",
    "print(\"mse :\", mse)\n",
    "print(\"acc :\", acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3열도 맞췄는데 1열은 거뜬..! \n",
    "-> 따라서 3가지 열이 있을때 2열이 가장 영향이 크다는 것을 알아서 잘 판단했다는 뜻이다\n",
    "(2열 영향력 100, 1,3열 영향력 0 을 판단해냈다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
