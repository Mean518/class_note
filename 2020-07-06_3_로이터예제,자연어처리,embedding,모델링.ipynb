{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test,y_test) = reuters.load_data(num_words=1000, test_split=0.2) # 가장 많이 쓰여진 단어 1000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) # 뉴스 데이터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]) # 첫번째 뉴스데이터의 길이(구의 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
       "       list([1, 2, 699, 2, 2, 56, 2, 2, 9, 56, 2, 2, 81, 5, 2, 57, 366, 737, 132, 20, 2, 7, 2, 49, 2, 2, 2, 2, 699, 2, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2, 2, 2, 775, 7, 48, 34, 191, 44, 35, 2, 505, 17, 12]),\n",
       "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 2, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 2, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 2, 55, 2, 92, 617, 80, 2, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 2, 7, 2, 81, 5, 187, 11, 15, 9, 2, 201, 5, 47, 2, 18, 478, 2, 5, 2, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]),\n",
       "       ...,\n",
       "       list([1, 141, 2, 387, 81, 8, 16, 2, 10, 340, 2, 850, 31, 56, 2, 691, 9, 2, 71, 9, 2, 2, 2, 699, 2, 2, 2, 699, 244, 2, 4, 49, 8, 4, 656, 850, 33, 2, 9, 2, 340, 2, 2, 9, 2, 22, 2, 2, 687, 83, 35, 15, 257, 6, 57, 2, 7, 4, 2, 654, 5, 2, 2, 2, 4, 49, 8, 16, 369, 646, 6, 2, 7, 124, 407, 17, 12]),\n",
       "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 2, 18, 14, 74, 134, 2, 18, 88, 2, 72, 11, 14, 2, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 2, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 2, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 2, 137, 336, 2, 6, 2, 142, 971, 2, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
       "       list([1, 227, 2, 91, 2, 125, 2, 21, 4, 2, 76, 7, 4, 757, 481, 2, 790, 2, 2, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 2, 91, 2, 2, 340, 7, 194, 2, 6, 2, 21, 127, 2, 2, 2, 6, 2, 4, 329, 433, 7, 65, 87, 2, 10, 2, 2, 290, 9, 21, 567, 16, 2, 24, 4, 76, 209, 30, 2, 2, 2, 8, 4, 60, 8, 4, 966, 308, 40, 2, 129, 2, 295, 277, 2, 9, 24, 286, 2, 234, 222, 9, 4, 906, 2, 2, 114, 2, 2, 7, 4, 113, 17, 12])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train  # texts_to_sequences 데이터로 구성되어 있음 -> 각자 길이는 다르니까 패딩작업은 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = max(y_train) + 1 \n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     3159\n",
       "4     1949\n",
       "19     549\n",
       "16     444\n",
       "1      432\n",
       "11     390\n",
       "20     269\n",
       "13     172\n",
       "8      139\n",
       "10     124\n",
       "9      101\n",
       "21     100\n",
       "25      92\n",
       "2       74\n",
       "18      66\n",
       "24      62\n",
       "0       55\n",
       "34      50\n",
       "36      49\n",
       "12      49\n",
       "28      48\n",
       "6       48\n",
       "30      45\n",
       "23      41\n",
       "31      39\n",
       "17      39\n",
       "40      36\n",
       "32      32\n",
       "41      30\n",
       "14      26\n",
       "39      24\n",
       "26      24\n",
       "43      21\n",
       "15      20\n",
       "29      19\n",
       "37      19\n",
       "38      19\n",
       "45      18\n",
       "5       17\n",
       "7       16\n",
       "27      15\n",
       "22      15\n",
       "42      13\n",
       "44      12\n",
       "33      11\n",
       "35      10\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pd = pd.DataFrame(y_train) # x인줄 알았는데 y네..!?..\n",
    "y_train_pd[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8982의 뉴스데이터를 46가지의 카테고리로 매칭하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩시키기\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=100, padding='pre') # 너무 긴게 있을수도 있으니 maxlen 사용\n",
    "x_test = pad_sequences(x_test, maxlen=100, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 100)\n",
      "(2246, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 46)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train3 = pad_sequences(y_train1)\n",
    "y_test3 = pad_sequences(y_test1)\n",
    "y에서 원핫 인코딩 대신 pad_sequences 쓸 수 없는 이유 :\n",
    "pad_sequences는 2중 list, 예를 들어 다양한 길이의 8000개 뉴스 기사데이터가 있을때 적용되는 함수임 (이러한 형태에서 사용한다는것을 기억하고 있어야 한다)\n",
    "지금 shape가 (8982,) 즉, 1차원인 y데이터에서는 1차원 -> 2차원의 0/1로 구성된 자릿값 원-핫 인코딩을 사용해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] # 3임"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 즉, 독립변수는 벡터화 시키고 (이건 임베딩이 대신 해줌)\n",
    "종속변수(분류의 경우)는 원-핫 인코딩 시켜야 한다는 말임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문) \n",
    "1) lstm,시계열 이런 키워드가 나왔는데 자연어처리랑 무슨 관련이 있는지? 막연히 최신 댓글이 더 영향력이 커서 그렇게 설명하신건가?\n",
    "아니면 input shape 필요없는거때문에 편리해서 쓰는건가?\n",
    "2) 종속변수도 임베딩으로 벡터화 시키면 안되나요..?!\n",
    "3) 로이터에서 pad_sequences 길이대로 임배딩 시키는게 제일 적합하다고 생각했는데 100이 아닌 1000으로 지정한 이유?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Flatten, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         10000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 66,494\n",
      "Trainable params: 66,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(1000, 100, input_length=100)) \n",
    "model.add(Embedding(100, 100))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) 임베딩 레이어 = 범주화 1000가지 & 아웃풋 노드 100\n",
    "2) lstm으로 받아서 flatten & input shape 필요없음 (그래서 주로 쓰는듯?)\n",
    "3) categorical은 46가지, softmax , categorical_crossentropy 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/100\n",
      "7185/7185 [==============================] - 3s 424us/step - loss: 1.2939 - acc: 0.6686 - val_loss: 1.4237 - val_acc: 0.6422\n",
      "Epoch 2/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.2523 - acc: 0.6789 - val_loss: 1.4660 - val_acc: 0.6322\n",
      "Epoch 3/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.2428 - acc: 0.6788 - val_loss: 1.4410 - val_acc: 0.6528\n",
      "Epoch 4/100\n",
      "7185/7185 [==============================] - 3s 377us/step - loss: 1.2379 - acc: 0.6804 - val_loss: 1.4297 - val_acc: 0.6511\n",
      "Epoch 5/100\n",
      "7185/7185 [==============================] - 3s 384us/step - loss: 1.2213 - acc: 0.6859 - val_loss: 1.4276 - val_acc: 0.6528\n",
      "Epoch 6/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 1.2206 - acc: 0.6857 - val_loss: 1.4466 - val_acc: 0.6522\n",
      "Epoch 7/100\n",
      "7185/7185 [==============================] - 3s 375us/step - loss: 1.2258 - acc: 0.6820 - val_loss: 1.4751 - val_acc: 0.6416\n",
      "Epoch 8/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 1.2112 - acc: 0.6843 - val_loss: 1.4750 - val_acc: 0.6411\n",
      "Epoch 9/100\n",
      "7185/7185 [==============================] - 3s 393us/step - loss: 1.2406 - acc: 0.6814 - val_loss: 1.4699 - val_acc: 0.6439\n",
      "Epoch 10/100\n",
      "7185/7185 [==============================] - 3s 389us/step - loss: 1.2244 - acc: 0.6811 - val_loss: 1.4526 - val_acc: 0.6489\n",
      "Epoch 11/100\n",
      "7185/7185 [==============================] - 3s 370us/step - loss: 1.2021 - acc: 0.6849 - val_loss: 1.4451 - val_acc: 0.6522\n",
      "Epoch 12/100\n",
      "7185/7185 [==============================] - 3s 377us/step - loss: 1.1953 - acc: 0.6880 - val_loss: 1.4484 - val_acc: 0.6450\n",
      "Epoch 13/100\n",
      "7185/7185 [==============================] - 3s 378us/step - loss: 1.1867 - acc: 0.6907 - val_loss: 1.4478 - val_acc: 0.6516\n",
      "Epoch 14/100\n",
      "7185/7185 [==============================] - 3s 385us/step - loss: 1.1754 - acc: 0.6909 - val_loss: 1.4511 - val_acc: 0.6500\n",
      "Epoch 15/100\n",
      "7185/7185 [==============================] - 3s 375us/step - loss: 1.1707 - acc: 0.6941 - val_loss: 1.4681 - val_acc: 0.6439\n",
      "Epoch 16/100\n",
      "7185/7185 [==============================] - ETA: 0s - loss: 1.1512 - acc: 0.699 - 3s 380us/step - loss: 1.1528 - acc: 0.7002 - val_loss: 1.4502 - val_acc: 0.6505\n",
      "Epoch 17/100\n",
      "7185/7185 [==============================] - 3s 378us/step - loss: 1.1515 - acc: 0.6984 - val_loss: 1.4800 - val_acc: 0.6450\n",
      "Epoch 18/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.1552 - acc: 0.6992 - val_loss: 1.4722 - val_acc: 0.6533\n",
      "Epoch 19/100\n",
      "7185/7185 [==============================] - 3s 384us/step - loss: 1.1491 - acc: 0.7003 - val_loss: 1.4719 - val_acc: 0.6472\n",
      "Epoch 20/100\n",
      "7185/7185 [==============================] - 3s 396us/step - loss: 1.1404 - acc: 0.7015 - val_loss: 1.4753 - val_acc: 0.6388\n",
      "Epoch 21/100\n",
      "7185/7185 [==============================] - 3s 388us/step - loss: 1.1391 - acc: 0.7010 - val_loss: 1.4848 - val_acc: 0.6472\n",
      "Epoch 22/100\n",
      "7185/7185 [==============================] - 3s 382us/step - loss: 1.1380 - acc: 0.6988 - val_loss: 1.4826 - val_acc: 0.6494\n",
      "Epoch 23/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 1.1217 - acc: 0.7080 - val_loss: 1.4947 - val_acc: 0.6444\n",
      "Epoch 24/100\n",
      "7185/7185 [==============================] - 3s 385us/step - loss: 1.1174 - acc: 0.7084 - val_loss: 1.5044 - val_acc: 0.6427\n",
      "Epoch 25/100\n",
      "7185/7185 [==============================] - 3s 382us/step - loss: 1.1189 - acc: 0.7047 - val_loss: 1.5364 - val_acc: 0.6494\n",
      "Epoch 26/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 1.1202 - acc: 0.7047 - val_loss: 1.5232 - val_acc: 0.6422\n",
      "Epoch 27/100\n",
      "7185/7185 [==============================] - 3s 390us/step - loss: 1.1063 - acc: 0.7116 - val_loss: 1.5124 - val_acc: 0.6494\n",
      "Epoch 28/100\n",
      "7185/7185 [==============================] - 3s 377us/step - loss: 1.1072 - acc: 0.7076 - val_loss: 1.5360 - val_acc: 0.6427\n",
      "Epoch 29/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.1023 - acc: 0.7083 - val_loss: 1.5105 - val_acc: 0.6411\n",
      "Epoch 30/100\n",
      "7185/7185 [==============================] - 3s 372us/step - loss: 1.1003 - acc: 0.7106 - val_loss: 1.5743 - val_acc: 0.6266\n",
      "Epoch 31/100\n",
      "7185/7185 [==============================] - 3s 384us/step - loss: 1.1457 - acc: 0.6881 - val_loss: 1.5272 - val_acc: 0.6366\n",
      "Epoch 32/100\n",
      "7185/7185 [==============================] - 3s 375us/step - loss: 1.1072 - acc: 0.7040 - val_loss: 1.5156 - val_acc: 0.6388\n",
      "Epoch 33/100\n",
      "7185/7185 [==============================] - 3s 375us/step - loss: 1.0883 - acc: 0.7126 - val_loss: 1.5206 - val_acc: 0.6444\n",
      "Epoch 34/100\n",
      "7185/7185 [==============================] - 3s 375us/step - loss: 1.0715 - acc: 0.7141 - val_loss: 1.5502 - val_acc: 0.6344\n",
      "Epoch 35/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 1.0663 - acc: 0.7143 - val_loss: 1.5774 - val_acc: 0.6361\n",
      "Epoch 36/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 1.0557 - acc: 0.7189 - val_loss: 1.5511 - val_acc: 0.6416\n",
      "Epoch 37/100\n",
      "7185/7185 [==============================] - 3s 382us/step - loss: 1.0539 - acc: 0.7189 - val_loss: 1.5331 - val_acc: 0.6416\n",
      "Epoch 38/100\n",
      "7185/7185 [==============================] - 3s 381us/step - loss: 1.0310 - acc: 0.7271 - val_loss: 1.5407 - val_acc: 0.6466\n",
      "Epoch 39/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.0244 - acc: 0.7241 - val_loss: 1.5436 - val_acc: 0.6383\n",
      "Epoch 40/100\n",
      "7185/7185 [==============================] - 3s 377us/step - loss: 1.0335 - acc: 0.7280 - val_loss: 1.5486 - val_acc: 0.6411\n",
      "Epoch 41/100\n",
      "7185/7185 [==============================] - 3s 380us/step - loss: 1.0341 - acc: 0.7232 - val_loss: 1.5624 - val_acc: 0.6427\n",
      "Epoch 42/100\n",
      "7185/7185 [==============================] - 3s 384us/step - loss: 1.0292 - acc: 0.7215 - val_loss: 1.5872 - val_acc: 0.6400\n",
      "Epoch 43/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 1.0193 - acc: 0.7279 - val_loss: 1.5900 - val_acc: 0.6450\n",
      "Epoch 44/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 1.0101 - acc: 0.7276 - val_loss: 1.5854 - val_acc: 0.6427\n",
      "Epoch 45/100\n",
      "7185/7185 [==============================] - 3s 379us/step - loss: 1.0129 - acc: 0.7282 - val_loss: 1.5908 - val_acc: 0.6405\n",
      "Epoch 46/100\n",
      "7185/7185 [==============================] - 3s 389us/step - loss: 0.9915 - acc: 0.7358 - val_loss: 1.5863 - val_acc: 0.6444\n",
      "Epoch 47/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 0.9801 - acc: 0.7376 - val_loss: 1.5967 - val_acc: 0.6439\n",
      "Epoch 48/100\n",
      "7185/7185 [==============================] - 3s 378us/step - loss: 0.9676 - acc: 0.7400 - val_loss: 1.6173 - val_acc: 0.6450\n",
      "Epoch 49/100\n",
      "7185/7185 [==============================] - 3s 380us/step - loss: 0.9640 - acc: 0.7402 - val_loss: 1.6211 - val_acc: 0.6455\n",
      "Epoch 50/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 0.9486 - acc: 0.7467 - val_loss: 1.6141 - val_acc: 0.6477\n",
      "Epoch 51/100\n",
      "7185/7185 [==============================] - 3s 381us/step - loss: 0.9507 - acc: 0.7442 - val_loss: 1.6919 - val_acc: 0.6383\n",
      "Epoch 52/100\n",
      "7185/7185 [==============================] - 3s 376us/step - loss: 0.9551 - acc: 0.7427 - val_loss: 1.6375 - val_acc: 0.6361\n",
      "Epoch 53/100\n",
      "7185/7185 [==============================] - 3s 377us/step - loss: 0.9517 - acc: 0.7427 - val_loss: 1.6522 - val_acc: 0.6383\n",
      "Epoch 54/100\n",
      "7185/7185 [==============================] - 3s 386us/step - loss: 0.9229 - acc: 0.7475 - val_loss: 1.6960 - val_acc: 0.6361\n",
      "Epoch 55/100\n",
      "7185/7185 [==============================] - 3s 380us/step - loss: 0.9232 - acc: 0.7481 - val_loss: 1.6974 - val_acc: 0.6427\n",
      "Epoch 56/100\n",
      "7185/7185 [==============================] - 3s 383us/step - loss: 0.9141 - acc: 0.7499 - val_loss: 1.7205 - val_acc: 0.6344\n",
      "Epoch 57/100\n",
      "6600/7185 [==========================>...] - ETA: 0s - loss: 0.9224 - acc: 0.7514"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-905ab13c6f1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'acc :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=200, validation_split=0.2)\n",
    "acc = model.evaluate(x_test,y_test)[1]\n",
    "print('acc :',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프로 학습곡선 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val_loss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "plt.plot(y_val_loss, marker='.', c='red', label='Test Loss')\n",
    "plt.plot(y_loss, marker='.', c='black', label='Train Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid();plt.xlabel('epoch');plt.ylabel('loss');plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
